{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bbfd9f",
   "metadata": {},
   "source": [
    "# PyTorch Practical Exercises\n",
    "\n",
    "**Topic:** Practical exercises to help solidify the concepts of using PyTorch to build neural networks.\n",
    "**Total Exercises:** 5\n",
    "**Estimated Time:** 3-5 hours\n",
    "\n",
    "---\n",
    "\n",
    "This notebook was generated from `PyTorch_practical_exercises.md`. Follow the sections in order and run code cells interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bdebae",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Environment & Setup](#environment--setup)\n",
    "2. [Exercise 1: Setting Up PyTorch](#exercise-1-setting-up-pytorch)\n",
    "3. [Exercise 2: Building a Simple Neural Network](#exercise-2-building-a-simple-neural-network)\n",
    "4. [Exercise 3: Training the Neural Network](#exercise-3-training-the-neural-network)\n",
    "5. [Exercise 4: Evaluating the Model](#exercise-4-evaluating-the-model)\n",
    "6. [Exercise 5: Advanced Practice - CIFAR & Transfer Learning](#exercise-5-advanced-practice---cifar--transfer-learning)\n",
    "7. [Notes and Next Steps](#notes-and-next-steps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e11699",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "| Objective | Skills Developed |\n",
    "|---|---|\n",
    "| Verify PyTorch installation | Importing PyTorch, checking versions and CUDA availability |\n",
    "| Build simple neural networks | Implementing `nn.Module`, layers and forward pass |\n",
    "| Train models | Data loading, training loop, optimizer and loss |\n",
    "| Evaluate models | Compute accuracy on test data |\n",
    "| Transfer learning | Load pretrained models and fine-tune final layers |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d8dd0",
   "metadata": {},
   "source": [
    "## Environment & Setup\n",
    "\n",
    "Use a virtual environment (venv or conda) and install the appropriate PyTorch build for your platform. For Google Colab, you can run `pip install torch torchvision` if required. The next cell verifies the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b62700",
   "metadata": {},
   "source": [
    "## Exercise 1: Setting Up PyTorch\n",
    "\n",
    "**Task:** Install PyTorch on your local machine or cloud environment and verify the installation by importing PyTorch and checking the version and CUDA availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f2832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b74af",
   "metadata": {},
   "source": [
    "## Exercise 2: Building a Simple Neural Network\n",
    "\n",
    "**Task:** Define a simple feedforward neural network using `nn.Module` for MNIST (flattened 28x28 inputs). The example below defines three linear layers (784 -> 128 -> 64 -> 10) and uses ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa6b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Input layer\n",
    "        self.fc2 = nn.Linear(128, 64)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(64, 10)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784dc51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the network\n",
    "model = SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e47bf",
   "metadata": {},
   "source": [
    "## Exercise 3: Training the Neural Network\n",
    "\n",
    "**Task:** Train the neural network on a simple dataset such as MNIST. The example training loop below uses CrossEntropyLoss and SGD. Reduce epochs for quick tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519c10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b0908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2992332791646324\n",
      "Epoch 2, Loss: 2.267253607813517\n",
      "Epoch 3, Loss: 2.1011886843363445\n",
      "Epoch 4, Loss: 1.8047558176676433\n",
      "Epoch 5, Loss: 1.6901330506006877\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, 6):  # 5 epochs\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten the images into vectors\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d1db7",
   "metadata": {},
   "source": [
    "## Exercise 4: Evaluating the Model\n",
    "\n",
    "**Task:** Evaluate the trained model on a validation/test set and report accuracy. The example below runs inference without gradients and computes accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f59d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.81%\n"
     ]
    }
   ],
   "source": [
    "testset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94591f46",
   "metadata": {},
   "source": [
    "## Exercise 5: Advanced Practice - CIFAR & Transfer Learning\n",
    "\n",
    "**Task:** Implement a CNN for CIFAR-10 and try transfer learning with a pretrained ResNet. Below are examples for loading CIFAR-10 and preparing a pretrained ResNet for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379c9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 classes: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a transformation to apply to the images\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Download and load the test dataset\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Classes in CIFAR-10\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "print(\"CIFAR-10 classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad2ff4",
   "metadata": {},
   "source": [
    "### Transfer learning (fine-tuning a pretrained ResNet)\n",
    "\n",
    "Load a pretrained ResNet, replace the final fully connected layer for 10 classes, and (optionally) freeze earlier layers. Ensure inputs are resized to 224x224 if using the standard pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929eec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nev4rb14su/.conda/envs/lab/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nev4rb14su/.conda/envs/lab/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load pretrained ResNet18\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "# Freeze pretrained parameters (optional)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer to match 10 classes\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Only train the final layer\n",
    "optimizer = optim.SGD(resnet.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(resnet)\n",
    "\n",
    "# Note: If using CIFAR images (32x32), consider upsampling to 224x224\n",
    "# or adapt the model input accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc029c9",
   "metadata": {},
   "source": [
    "## Notes and Next Steps\n",
    "\n",
    "- For quick experiments set small epochs and batch sizes; increase them for final runs.\n",
    "- Add model checkpointing (torch.save) and evaluation logging for reproducibility.\n",
    "- Extend the notebook with visualization of training/validation loss and accuracy.\n",
    "- If you want, I can split this notebook into smaller cells with more comments or add full training scripts for transfer learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
